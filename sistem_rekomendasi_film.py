# -*- coding: utf-8 -*-
"""sistem_rekomendasi_film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T8RdlV8yLylzi0RRmvdJD_4BM_ItnzsO

# Project Overview

Perkembangan layanan streaming video seperti Netflix, Disney+, dan Amazon Prime membuat jumlah film dan serial TV yang tersedia sangat banyak. Pengguna sering bingung memilih tontonan yang sesuai preferensi mereka. Sistem rekomendasi yang memanfaatkan rating pengguna saja terkadang kurang akurat karena bisa bias dan tidak mempertimbangkan sentimen review serta tren terkini di sosial media. Oleh karena itu, proyek ini bertujuan membangun sistem rekomendasi yang menggabungkan data rating, analisis sentimen review film/series, dan tren sosial media untuk memberikan rekomendasi yang lebih relevan dan up-to-date.

referensi:


*   [Sistem Rekomendasi Film Menggunakan Content Based Filtering](https://j-ptiik.ub.ac.id/index.php/j-ptiik/article/view/9163)
*   [Sistem Rekomendasi Film Menggunakan Metode Hybrid Collaborative Filtering Dan Content-based Filtering](https://openlibrarypublications.telkomuniversity.ac.id/index.php/engineering/article/view/18066)

# Business Understanding

## Problem Statements

1. Pengguna kesulitan memilih film yang sesuai dengan selera mereka di platform streaming.
2. Data rating saja tidak cukup untuk memberikan rekomendasi yang relevan karena bisa bias.
3. Tren sosial media belum dimanfaatkan secara maksimal dalam sistem rekomendasi.

## Goals

1. Membangun sistem rekomendasi film yang menggabungkan rating pengguna, analisis sentimen review, dan tren sosial media.
2. Memastikan rekomendasi yang diberikan lebih relevan dengan selera pengguna dan tren terkini.
3. Mengurangi bias dalam rekomendasi dengan memanfaatkan data sosial media.

## Solution Approach

1. **Content-Based Filtering**: Menggunakan informasi yang ada di film, seperti genre dan deskripsi, untuk merekomendasikan film yang serupa dengan yang sudah dilihat pengguna.
2. **Collaborative Filtering**: Menggunakan data rating dari pengguna lain untuk memberikan rekomendasi berdasarkan kesamaan preferensi antar pengguna.

# Data Understanding

Dataset yang digunakan dalam proyek ini terdiri dari 4 file utama:

1. **movies.csv** - Berisi informasi film, seperti `movieId`, `title`, dan `genres`.
2. **ratings.csv** - Berisi data rating film yang diberikan oleh pengguna, dengan kolom `userId`, `movieId`, `rating`, dan `timestamp`.
3. **tags.csv** - Berisi tag atau kata kunci yang diberikan pengguna pada film tertentu.

## Variabel/ Fitur:
- **movies.csv**:
  - `movieId`: ID unik untuk setiap film.
  - `title`: Judul film.
  - `genres`: Kategori genre yang dimiliki film, dipisah dengan tanda `|`.
- **ratings.csv**:
  - `userId`: ID unik untuk setiap pengguna.
  - `movieId`: ID film yang diberi rating oleh pengguna.
  - `rating`: Rating yang diberikan pengguna terhadap film (skala 1-5).
  - `timestamp`: Waktu pengguna memberikan rating.
- **tags.csv**:
  - `userId`: ID pengguna yang memberikan tag.
  - `movieId`: ID film yang diberi tag.
  - `tag`: Kata kunci atau tag yang diberikan pengguna.
  - `timestamp`: Waktu pemberian tag.

# Import Libary
"""

!pip install annoy

!pip install scikit-surprise

from annoy import AnnoyIndex

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import hstack



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD

import warnings
warnings.filterwarnings('ignore')

"""# Data Load"""

# Load dataset
movies = pd.read_csv('/content/drive/MyDrive/Coding Camp - DBS Fundation/Machine Learning Terapan/Submission Kedua/dataset/movies.csv')
ratings = pd.read_csv('/content/drive/MyDrive/Coding Camp - DBS Fundation/Machine Learning Terapan/Submission Kedua/dataset/ratings.csv')
tags = pd.read_csv('/content/drive/MyDrive/Coding Camp - DBS Fundation/Machine Learning Terapan/Submission Kedua/dataset/tags.csv')

# --- Tampilkan contoh data ---
print("=== Contoh data movies.csv ===")
print(movies.head(), '\n')

print("=== Contoh data ratings.csv ===")
print(ratings.head(), '\n')

print("=== Contoh data tags.csv ===")
print(tags.head(), '\n')

"""# EDA (Data Exploratory Analysis)

## Movies Variable

`movies` merupakan variabel yang berisikan informasi mengenai **ID Movies, Judul Movies, Genre Movies,** serta **Tahun Tayang Movies**
"""

print(movies.head())

movies.info()

"""`movies.info()` memberikan informasi mengenai tipe data dan jumlah data yang hilang (missing values) untuk setiap kolom.

Jumlah rom / baris data ini yaitu sebanyak **9742** data dan tidak tidak memiliki **missing value** ditunjukkan pada *non-null*

Pada dataset tersebut memiliki **2** tipe data berbentuk **object** dan **1** tipe data berbentuk **int**.
"""

movies.describe()

"""pada kolom `movieId` memiliki rentang nilai dengan minimal *1* dan maksimal *193609*"""

movies.duplicated().sum()

"""hasil diatas menunjukkan bahwa tidak ada **data duplikat**"""

print(f"Total movies: {movies['title'].nunique()}")

"""berdasarkan informasi diatas bertujuan untuk mengetahui jumlah movies yang **unique**, yaitu terdapat 9737 Movies yang berbeda berdasarkan *title*"""

genre_list = movies['genres'].str.split('|').explode()

print("\nTop 10 Genre Film:")
print(genre_list.value_counts().head(10))

"""berdasarkan informasi diatas , top 10 genre yang paling banyak ditampilkan :

1.   Drama dengan **4361** movie
2.   Comedy dengan **3756** movie
3.   Thriller dengan **1894** movie
4.   Action dengan **1828** movie
5.   Romance dengan **1596** movie
6.   Adventure dengan **1263** movie
7.   Crime dengan **1199** movie
8.   Sci-Fi dengan **980** movie
9.   Horror dengan **978** movie
10.  Fantasy dengan **779** movie


"""

print(f"Jumlah movieId unik di movies: {movies['movieId'].nunique()}")
print(f"Jumlah total baris di movies: {len(movies)}")

# Cek baris duplikat movieId
duplicates = movies[movies.duplicated(subset=['movieId'], keep=False)]
print("Baris duplikat berdasarkan movieId di movies:")
print(duplicates)

"""## Ratings Variabels

`ratings` merupakan variabel yang memberikan informasi mengenai penilaian user terkait movie yang ditonton dengan memberikan angka 1 - 5
"""

print(ratings.head())

ratings.info()

"""`ratings.info()` menunjukkan informasi mengenai banyaknya **kolom**, **jumlah data**, **jumlah data kosong**, dan **tipe data kolom**

Hasil menunjukkan terdapat 4 kolom yaitu *userId, movieId, rating, dan timestamp*,
 yang mana 3 bertipe data
**int** (userId,movieId, dan timestamp) dan 1 **float**(rating)
"""

ratings.describe()

"""berdasarkan informasi dari `describe()` yang memberikan informasi statistik pada masing-masing kolom numerik

`rating` merupakan penilaian terhadap suatu movie oleh user yang mana menunjukkan minimal user memberikan rating 1 dan maksimal 5 , dengan rata-rata yaitu 3.5
"""

ratings.duplicated().sum()

"""hasil diatas menunjukkan bahwa tidak ada **data duplikat**"""

jumlah_user = ratings['userId'].nunique()
jumlah_movie = ratings['movieId'].nunique()

print(f"Jumlah User: {jumlah_user}")
print(f"Jumlah Movie: {jumlah_movie}")

"""`jumlah_user` merupakan variabel yang menampung jumlah nilai unik pada kolom `userId` dengan jumlah **610** user yang sudah mengisi rating

`jumlah_movie` merupakan variabel yang menampung jumlah nilai unik pada kolom `movie` dengan jumlah **9724** movies yang sudah dinilai oleh user
"""

ratings.head()

# cek user apakah mengisi rating movie yang sama lebih dari 1 kali
print(ratings.groupby(['userId','movieId']).size().max())

# Visualisasi Persebaran berdasarkan ratings

plt.figure(figsize=(8, 6))
sns.countplot(x='rating', data=ratings)
plt.title('Persebaran Rating Film')
plt.xlabel('Rating')
plt.ylabel('Jumlah Film')
plt.show()

"""## Tags Variabel

`tags` merupakan variabel yang memberikan informasi mengenai penilaian *user* terhadap *movie* tentang gambaran mengenai movie tersebut.
"""

print(tags.head())

tags.info()

tags.duplicated().sum()

"""hasil diatas menunjukkan bahwa tidak ada **data duplikat**"""

jumlah_movie = tags['movieId'].nunique()
jumlah_user = tags['userId'].nunique()
jumlah_tag = tags['tag'].nunique()

print(f"Jumlah User: {jumlah_user}")
print(f"Jumlah Movie: {jumlah_movie}")
print(f"Jumlah Tag: {jumlah_tag}")

"""berdasarkan informasi diatas, jumlah user yang memberikan tags sebanyak **58** user *unik*, kemudian jumlah movie yang diberikan tags sebanyak **1572** tags, dan jumlah tags yang diberikan oleh user sebanyak **1589**   """

# Cek apakah user bisa menambahkan lebih dari tag pada movies yang sama
print(tags.groupby(['userId','movieId']).size().max())

"""# Data Preparation

## Movies Variable

### Memisahkan genre menjadi list
"""

# Memisahkan genres kedalam daftar list

movies['genres'] = movies['genres'].str.split('|')

movies.head()

"""### Memisahkan title dengan tahun rilis"""

# Memisahkan title dengan tahun rilis

movies['year'] = movies['title'].str.extract(r'\((\d{4})\)', expand=False)
movies['title'] = movies['title'].str.replace(r'\s*\(\d{4}\)', '', regex=True).str.strip()


movies.sample(10)

"""### Memberikan nilai pada data tahun yang kosong"""

# Memberikan nilai pada data yang tidak memiliki tahun
movies['year'] = movies['year'].fillna(0).astype(int)

movies.head()

movies.isna().sum()

"""## Ratings Variable

### Drop kolom timestamp
"""

ratings = ratings.drop(['timestamp'], axis=1)

ratings.head()

ratings.info()

ratings.duplicated().sum()

"""## Tags Variable"""

print(tags.groupby(['userId','movieId']).size().max())

"""### Menggabungkan tag yang diberikan user pada movies yang sama"""

tags_agg = tags.groupby(['userId', 'movieId'])['tag'].apply(lambda x: ','.join(x.unique())).reset_index()

tags_agg.head()

tags_agg['tag'] = tags_agg['tag'].fillna('no_tag')

tags_agg.head()

tags_agg = tags_agg.drop_duplicates()

tags_agg.head()

tags_agg['tag'] = tags_agg['tag'].str.split(',')

tags_agg.head()

"""## Menggabungkan Ratings dengan Tags

"""

ratings_tags = pd.merge(ratings, tags_agg, on=['userId', 'movieId'], how='left')

ratings_tags.head()

ratings_tags.info()

ratings_tags['tag'] = ratings_tags['tag'].fillna('no_tag')

ratings_tags.head()

ratings_tags.info()

"""## Menggabungkan Seluruh Data"""

full_data = pd.merge(ratings_tags, movies, on='movieId', how='left')

full_data.head()

"""## Data Preparation untuk Content-Based Filtering (CBF)

### Menggabungkan Tags ke dalam satu string
"""

def clean_and_join_tags(tag_lists):
    """
    Menerima Series yang berisi list tag per film dari beberapa user,
    menggabungkan tag menjadi string, dan melewati tag 'no_tag'.
    """
    cleaned_tags = []
    for tags in tag_lists:
        # Pastikan tags adalah list, jika tidak buat list kosong
        if isinstance(tags, list):
            # Filter hapus 'no_tag'
            filtered = [tag.strip() for tag in tags if tag.strip().lower() != 'no_tag']
            cleaned_tags.extend(filtered)
    # Gabungkan menjadi satu string
    if len(cleaned_tags) == 0:
        return ''  # jika tidak ada tag selain no_tag
    return ' '.join(cleaned_tags)

# Cara pakai pada dataframe full_data:
tags_per_movie = full_data.groupby('movieId')['tag'].apply(clean_and_join_tags).reset_index()

print(tags_per_movie.head())

"""Pada fungsi diatas menggabungkan `tags` kedalam satu string yang sama jika terdapat lebih dari 1 tag pada `movie` yang sama.

### TF-IDF
"""

tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
tfidf_matrix = tfidf_vectorizer.fit_transform(tags_per_movie['tag'])

print(f"Shape TF-IDF matrix: {tfidf_matrix.shape}")

"""TF-IDF digunakan untuk mengubah data `tag` menjadi matriks vektor yang dapat digunakan dalam pemodelan CBF. Matriks vektor ini akan digunakan sebagai fitur atribut film dalam CBF. dengan menambahkan parameter `stop_words='english'` dan `max_features=1000` untuk menghilangkan kata-kata yang tidak memiliki makna dan mengambil 1000 fitur tertinggi.

## Data Preparation untuk Collaboration Filtering (CF)
"""

df_rating = ratings

df_rating.head()

df_rating.info()

"""#### Mengacak Data"""

# Mengacak dataset
df_rating = df_rating.sample(frac=1, random_state=42)
df_rating

"""#### Split Data"""

min_rating = df_rating['rating'].min()
max_rating = df_rating['rating'].max()

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df_rating[['userId', 'movieId']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df_rating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""#### Mapping Data"""

# Mapping userId dan movieId ke indeks embedding
user_ids = df_rating['userId'].unique().tolist()
user_to_index = {user_id: index for index, user_id in enumerate(user_ids)}
index_to_user = {index: user_id for index, user_id in enumerate(user_ids)}

movie_ids = df_rating['movieId'].unique().tolist()
movie_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}
index_to_movie = {index: movie_id for index, movie_id in enumerate(movie_ids)}

# Terapkan mapping ke data training dan validasi
x_train[:, 0] = [user_to_index[user_id] for user_id in x_train[:, 0]]
x_val[:, 0] = [user_to_index[user_id] for user_id in x_val[:, 0]]

x_train[:, 1] = [movie_to_index[movie_id] for movie_id in x_train[:, 1]]
x_val[:, 1] = [movie_to_index[movie_id] for movie_id in x_val[:, 1]]

# The number of unique users and movies should be based on the number of unique entries in the original data
num_users = len(user_ids)
num_movies = len(movie_ids)

"""# Modelling

## Content-Based Filtering

### Cosine Similarity
"""

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print(f"Shape cosine similarity matrix: {cosine_sim.shape}")

"""Menghitung Cosine Similarity antara setiap baris (movie) dalam matrix TF-IDF. Cosine Similarity digunakan untuk mengukur kemiripan antara dua vektor. Dalam konteks ini, kita ingin menemukan movie yang mirip dengan movie lainnya berdasarkan *tags* mereka.

Cosine Similarity mengukur kemiripan antara dua vektor berdasarkan sudut (bukan panjangnya).

Nilai berada di antara `-1` hingga `1`:

`1` → sangat mirip (arah vektor sama)

`0` → tidak mirip (tegak lurus)

`-1` → berlawanan (jarang terjadi di NLP)

**Rumus Cosine Similarity**

$$
\text{cosine_similarity}(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}
$$

Keterangan:
- $ A \cdot B $: dot product antara vektor A dan B  
- $ \|A\| $: panjang (norma) dari vektor A  
- $ \|B\| $: panjang (norma) dari vektor B

### Inferensi
"""

def get_recommendations_by_tag(movie_id, top_n=5):
    # Cari indeks film
    idx = tags_per_movie[tags_per_movie['movieId'] == movie_id].index[0]

    # Hitung similarity film lain
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Urutkan berdasarkan similarity tertinggi
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Ambil top-n film paling mirip, kecuali film itu sendiri
    sim_scores = sim_scores[1:top_n+1]

    # Ambil indeks film rekomendasi
    movie_indices = [i[0] for i in sim_scores]

    # Ambil movieId dan judul film dari dataframe movies (yang sudah kamu siapkan)
    recommended_ids = tags_per_movie.iloc[movie_indices]['movieId'].values
    recommended_movies = movies[movies['movieId'].isin(recommended_ids)][['movieId', 'title']].drop_duplicates()

    return recommended_movies


def recommend_by_title_tag():
    movie_name = input("Masukkan judul film: ").strip().lower()

    # Cari movieId berdasarkan judul (case insensitive)
    matched = movies[movies['title'].str.lower() == movie_name]

    if matched.empty:
        print(f"Film dengan judul '{movie_name}' tidak ditemukan. Coba lagi.")
        return

    movie_id = matched.iloc[0]['movieId']
    print(f"Film yang dipilih: {matched.iloc[0]['title']}")

    recommendations = get_recommendations_by_tag(movie_id)

    if recommendations.empty:
        print("Tidak ada rekomendasi yang tersedia.")
    else:
        print("Rekomendasi film serupa berdasarkan tag:")
        for idx, row in recommendations.iterrows():
            print(f"- {row['title']} (movieId: {row['movieId']})")

# Jalankan fungsi input rekomendasi
recommend_by_title_tag()

"""## Collaborative Filterring

### Proses Training
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movies_embedding = layers.Embedding( # layer embeddings movies
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movies_bias = layers.Embedding(num_movies, 1) # layer embedding movies bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movies_vector = self.movies_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movies_bias = self.movies_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movies = tf.tensordot(user_vector, movies_vector, 2)

    x = dot_user_movies + user_bias + movies_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Data userId dan movieId diubah menjadi indeks numerik agar dapat digunakan sebagai input embedding pada model neural network."""

model = RecommenderNet(num_users, num_movies, 50) # inisialisasi model

earlystopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # inisialisasi earlystopping

checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True) # inisialisasi checkpoint

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]

)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    callbacks = [earlystopping, checkpoint],
    validation_data = (x_val, y_val)
)

"""Model dilatih dengan optimasi binary crossentropy dan menggunakan root mean squared error (RMSE) sebagai metrik evaluasi. Early stopping dan checkpoint digunakan untuk mencegah overfitting dan menyimpan model terbaik.

### Visualisasi Metrik
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Grafik ini menunjukkan perkembangan performa model selama training. RMSE yang menurun menandakan model semakin baik dalam memprediksi rating.

### Inferensi
"""

def get_collaborative_recommendations(user_id, top_n=5):
      # Cek apakah user_id ada di mapping
      if user_id not in user_to_index:
          print(f"UserId {user_id} tidak ditemukan.")
          return None

      user_idx = user_to_index[user_id]

      # Semua movie index
      all_movie_indices = list(range(num_movies))

      # Movie yang sudah dirating user
      rated_movie_ids = df_rating[df_rating['userId'] == user_id]['movieId'].unique()
      rated_movie_indices = [movie_to_index[movie_id] for movie_id in rated_movie_ids if movie_id in movie_to_index]

      # Movie yang belum dirating user
      unrated_movie_indices = [i for i in all_movie_indices if i not in rated_movie_indices]

      # Prediksi rating untuk film belum dirating user
      predictions = []
      batch_size = 1000  # untuk efisiensi, prediksi batch

      for start in range(0, len(unrated_movie_indices), batch_size):
          end = min(start + batch_size, len(unrated_movie_indices))
          batch_movie_indices = unrated_movie_indices[start:end]
          batch_user_indices = [user_idx] * len(batch_movie_indices)

          inputs = np.array([batch_user_indices, batch_movie_indices]).T
          preds = model.predict(inputs).flatten()

          for movie_idx, pred_rating in zip(batch_movie_indices, preds):
              predictions.append((movie_idx, pred_rating))

      # Urutkan berdasarkan prediksi rating tertinggi
      predictions.sort(key=lambda x: x[1], reverse=True)

      # Ambil top_n rekomendasi
      top_predictions = predictions[:top_n]

      # Ambil movieId dari index
      recommended_movie_ids = [index_to_movie[movie_idx] for movie_idx, _ in top_predictions]

      # Ambil judul film dari dataframe movies
      recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)][['movieId', 'title', 'year']].drop_duplicates()

      return recommended_movies

def recommend_collaborative():
    user_id_input = input("Masukkan userId untuk mendapatkan rekomendasi: ").strip()

    # Coba konversi input ke int, jika gagal langsung return error
    try:
        user_id = int(user_id_input)
    except ValueError:
        print("Input userId harus berupa angka.")
        return

    # Cek apakah user_id ada di data
    if user_id not in user_to_index:
        print(f"UserId {user_id} tidak ditemukan dalam data.")
        return

    recommendations = get_collaborative_recommendations(user_id, top_n=5)

    if recommendations is not None and not recommendations.empty:
        print(f"Rekomendasi film untuk userId {user_id}:")
        for _, row in recommendations.iterrows():
            print(f"- {row['title']} {row['year']} (movieId: {row['movieId']})")
    else:
        print(f"Tidak ada rekomendasi yang ditemukan untuk userId {user_id}.")

df_rating.head()

# Jalankan fungsi input interaktif
recommend_collaborative()